# Shared parameters for multiple nodes
/**:
  ros__parameters:
    # Transformation from sensor to world frame
    lidar2world_transform:
      # [x,y,z] in meters
      translation: [0.0, 0.0, 3.05]

      # [w,x,y,z] normalized quaternion
      quaternion: [0.983532, 0.022803, 0.014310, 0.178719]

# These parameters are dependant on the sensor location
# Note: For converting angles use https://www.andre-gaschler.com/rotationconverter/
perception_node:
  ros__parameters:
    # The crop box isolates a region of interest in the pointcloud
    # all point outside this box are removed
    # Use the roi_visulaizer.py tool to find a new crop_box params if needed
    crop_box_transform:
      # [x,y,z] in meters
      translation: [23.5, 17.0, 1.4]

      # [w,x,y,z] normalized quaternion
      quaternion: [1.0, 0.0, 0.0, 0.0]

      # [x, y, z] in meters
      size: [19.0, 66.0, 3.3]


projection_node:
  ros__parameters:
    # Matrix from intrinsic camera calibration
    # This day's data was recorded at 1920x1080
    camera_matrix: [1199.821557, 0.000000, 960.562236, 0.000000, 1198.033465, 551.675808, 0.000000, 0.000000, 1.000000]

    # Transform from Lidar to camera frame
    lidar2cam_extrinsic:
      rotation: [0.0, 1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0]
      translation: [-0.05, 0.05, 0.0]

    # Transform from lidar data from to lidar sensor frame
    # See https://github.com/ros-drivers/ros2_ouster_drivers/issues/87
    # The translation part may already be accounted for internally in the driver
    lidarData2lidarSensor_extrinsic:
      rotation: [-1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0]
      translation: [0.0, 0.0, 0.03618]

camera_det3d:
  ros__parameters:

    # Transformation from sensor to world frame
    lidar2world_transform:
      # [x,y,z] in meters
      translation: [0.0, 0.0, 3.0]

      # [w,x,y,z] normalized quaternion
      quaternion: [0.983532, 0.022803, 0.014310, 0.178719]

    # Matrix from intrinsic camera calibration
    # This day's data was recorded at 1920x1080
    camera_matrix: [1199.821557, 0.000000, 960.562236, 0.000000, 1198.033465, 551.675808, 0.000000, 0.000000, 1.000000]

    # Transform from Lidar to camera frame
    lidar2cam_extrinsic:
      rotation: [0.0, 1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0]
      translation: [-0.05, 0.05, 0.0]

    # Transform from lidar data from to lidar sensor frame
    # See https://github.com/ros-drivers/ros2_ouster_drivers/issues/87
    # The translation part may already be accounted for internally in the driver
    lidarData2lidarSensor_extrinsic:
      rotation: [-1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0]
      translation: [0.0, 0.0, 0.03618]
